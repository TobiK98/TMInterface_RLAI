# import TM stuff
import sys
from time import time
from tminterface.interface import TMInterface
from tminterface.client import Client, run_client

# import others
import numpy as np


class Q_Agent(Client):
    def __init__(self) -> None:
        super(Q_Agent, self).__init__()
        self.state = np.array([427, 368])
        self.prev_state = np.array([427, 368])
        self.actions = np.arange(4)
        self.q = np.zeros([260, 28, 4])
        self.learning_rate = 0.1
        self.epsilon = 0.9
        self.epsilon_decay = 0.98
        self.discount = 0.95
        self.current_episode = 0
        self.episode_reward = 0
        self.rewards = 0
        self.cp_states = np.zeros(8)
        self.prev_cp_states = np.zeros(8)
        self.marker = False

    # register to TM
    def on_registered(self, iface: TMInterface) -> None:
        print(f'Registered to {iface.server_name}')

    # step
    def on_run_step(self, iface: TMInterface, _time: int):
        if _time >= 0 and _time % 50 == 0:
            if np.random.random() < self.epsilon:
                action = np.random.choice(self.actions)
                print('RANDOM')
            else:
                action = np.argmax(self.q[self.state[0] - 427][self.state[1] - 370])
                print('ERFAHRUNG', action)
                print(np.argmax(self.q[self.state[0] - 427][self.state[1] - 370]))

            if action == 0:
                iface.set_input_state(left=False, accelerate=True, right=False, brake=False)
            if action == 1:
                iface.set_input_state(left=True, accelerate=True, right=False, brake=False)
            if action == 2:
                iface.set_input_state(left=False, accelerate=True, right=True, brake=False)
            if action == 3:
                iface.set_input_state(left=False, accelerate=True, right=False, brake=True)

            self.prev_state = self.state
            game_data = iface.get_simulation_state().position
            self.state[0] = np.round(game_data[2]).astype(int)
            self.state[1] = np.round(game_data[0]).astype(int)

            self.prev_cp_states = self.cp_states
            self.cp_states = iface.get_checkpoint_state().cp_states

            reward = 0
            if self.state[0] > self.prev_state[0]:
                reward += +2
            else:
                reward += -5
            if 365 <= self.state[1] <= 371:
                reward += +5
            else:
                reward += -10
            if self.state[1] <= 357 or self.state[1] >= 379:
                reward += -5000 + self.state[0] * 5
                self.marker = True
            if sum(self.cp_states) > sum(self.prev_cp_states):
                reward += 100
            self.episode_reward += reward

            current_q = self.q[self.state[0] - 427][self.state[1] - 370][action]
            max_future_q = np.max(self.q[self.state[0] - 427][self.state[1] - 370])
            new_q = current_q + self.learning_rate * (reward + (self.discount * max_future_q) - current_q)
            #new_q = (1 - self.learning_rate) * current_q + self.learning_rate * (reward + self.discount * max_future_q)
            self.q[self.state[0] - 427][self.state[1] - 370][action] = new_q

            if _time >= 12000 or sum(iface.get_checkpoint_state().cp_states) == 8 or self.marker is True:
                self.reset()
                iface.give_up()
        

    def reset(self):
        print(f'===== Finished episode {self.current_episode} =====')
        print(f'Episode reward: {self.episode_reward}')
        self.rewards = np.append(self.rewards, self.episode_reward)
        print(f'Average reward: {np.mean(self.rewards)}\n')
        self.state = np.array([427, 368])
        self.prev_state = np.array([427, 368])
        self.current_episode += 1
        self.episode_reward = 0
        self.epsilon *= self.epsilon_decay
        self.marker = False
            

            

    # let game play when goal reached
    def on_checkpoint_count_changed(self, iface: TMInterface, current: int, target: int):
        if current == target:
            iface.prevent_simulation_finish()



agent = Q_Agent()

# connect to TM
def main():
    server_name = f'TMInterface{sys.argv[1]}' if len(sys.argv) > 1 else 'TMInterface0'
    print(f'Connecting to {server_name}...')
    run_client(agent, server_name)

if __name__ == '__main__':
    main()